{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ddb150",
   "metadata": {},
   "source": [
    "A confusion matrix provides the foundation for several important metrics used to evaluate the performance of a classification model. These metrics each offer a different perspective on how well the model is performing. Here are some of the most common metrics:\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Measures the proportion of total correct predictions (both positives and negatives).\n",
    "Calculation: \n",
    "Accuracy\n",
    "=\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Accuracy= \n",
    "TP+TN+FP+FN\n",
    "TP+TN\n",
    "​\n",
    " \n",
    "Precision (Positive Predictive Value)\n",
    "\n",
    "Measures the proportion of positive identifications that were actually correct.\n",
    "Calculation: \n",
    "Precision\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Precision= \n",
    "TP+FP\n",
    "TP\n",
    "​\n",
    " \n",
    "Recall (Sensitivity, True Positive Rate)\n",
    "\n",
    "Measures the proportion of actual positives that were identified correctly.\n",
    "Calculation: \n",
    "Recall\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Recall= \n",
    "TP+FN\n",
    "TP\n",
    "​\n",
    " \n",
    "F1 Score\n",
    "\n",
    "Harmonic mean of precision and recall. It's a balance between precision and recall.\n",
    "Calculation: \n",
    "F1 Score\n",
    "=\n",
    "2\n",
    "×\n",
    "Precision\n",
    "×\n",
    "Recall\n",
    "Precision\n",
    "+\n",
    "Recall\n",
    "F1 Score=2× \n",
    "Precision+Recall\n",
    "Precision×Recall\n",
    "​\n",
    " \n",
    "Specificity (True Negative Rate)\n",
    "\n",
    "Measures the proportion of actual negatives that were identified correctly.\n",
    "Calculation: \n",
    "Specificity\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Specificity= \n",
    "TN+FP\n",
    "TN\n",
    "​\n",
    " \n",
    "False Positive Rate\n",
    "\n",
    "Measures the proportion of actual negatives that were incorrectly classified as positives.\n",
    "Calculation: \n",
    "False Positive Rate\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "False Positive Rate= \n",
    "TN+FP\n",
    "FP\n",
    "​\n",
    " \n",
    "Negative Predictive Value\n",
    "\n",
    "Measures the proportion of negative identifications that were actually correct.\n",
    "Calculation: \n",
    "Negative Predictive Value\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Negative Predictive Value= \n",
    "TN+FN\n",
    "TN\n",
    "​\n",
    " \n",
    "False Discovery Rate\n",
    "\n",
    "Measures the proportion of positive predictions that were false.\n",
    "Calculation: \n",
    "False Discovery Rate\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "False Discovery Rate= \n",
    "TP+FP\n",
    "FP\n",
    "​\n",
    " \n",
    "Miss Rate (False Negative Rate)\n",
    "\n",
    "Measures the proportion of positives that were incorrectly classified as negatives.\n",
    "Calculation: \n",
    "Miss Rate\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "Miss Rate= \n",
    "TP+FN\n",
    "FN\n",
    "​\n",
    " \n",
    "Context and Application\n",
    "Accuracy: Useful when the class distribution is similar or when the costs of FP and FN are roughly the same.\n",
    "Precision and Recall: Important in scenarios where FP and FN have different implications. For example, recall is crucial in medical diagnosis tests.\n",
    "F1 Score: Used when there is a need to balance precision and recall, especially in cases of uneven class distribution.\n",
    "Specificity and False Positive Rate: Particularly relevant in scenarios where false alarms (FP) are a significant concern.\n",
    "Each of these metrics provides a different view of the model's performance and should be selected based on the specific needs and context of the problem being addressed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
