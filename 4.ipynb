{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7e5258",
   "metadata": {},
   "source": [
    "Data leakage refers to a situation in machine learning where information from outside the training dataset is used to create the model. This can lead to overly optimistic performance estimates during training, but poor performance when the model is deployed in a real-world setting. Preventing data leakage is crucial for building robust and reliable models. Here are several strategies to prevent it:\n",
    "\n",
    "1. Understand the Data\n",
    "Source Knowledge: Understand where the data comes from and what each feature represents. This helps in identifying features that might inadvertently leak information about the target variable.\n",
    "\n",
    "Temporal Dynamics: Be careful with time-series data. Ensure that future data is not used to predict past or current events.\n",
    "\n",
    "2. Careful Feature Engineering\n",
    "Avoid using features that can indirectly contain information about the target variable. For instance, if you are predicting whether a patient will develop a disease, donâ€™t include features like 'Medication Prescribed' which will only be known after the diagnosis.\n",
    "3. Proper Data Splitting\n",
    "Split the data into training and testing sets before any data preprocessing or feature selection. This ensures that the data used for model validation is not influenced by the training process.\n",
    "\n",
    "For time-series data, make sure that the training set only includes data from before the test set period.\n",
    "\n",
    "4. Avoid Data Snooping\n",
    "Data snooping occurs when a model is indirectly influenced by the test data. This can happen through repeated model tuning and validation on the same test set. To avoid this, use a separate validation set or techniques like cross-validation.\n",
    "5. Cross-Validation\n",
    "Use cross-validation techniques properly. Make sure that data preprocessing steps like normalization or feature selection are included within the cross-validation loops, not applied beforehand.\n",
    "6. Pipelines\n",
    "In software tools like Scikit-Learn, use pipelines to ensure that preprocessing (like scaling, normalization, or PCA) is done separately on training and validation/test data within each cross-validation fold or data split.\n",
    "7. Be Wary of Target Leakage\n",
    "Target leakage occurs when you include data in the features that will not be available at prediction time. Ensure that the features used for training will be available in the deployment environment with the same characteristics.\n",
    "8. Regularization and Model Complexity\n",
    "Simpler models are less likely to pick up noise and subtle data leakages. Use regularization techniques to avoid overly complex models that fit the idiosyncrasies of the training data.\n",
    "9. Review Data Collection and Integration Processes\n",
    "If combining data from different sources, ensure that the integration process does not inadvertently introduce leakage, such as merging future information.\n",
    "10. External Validation\n",
    "If possible, validate the model on a completely separate external dataset that was not used in any part of the training or model selection process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
